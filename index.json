[{"authors":["admin"],"categories":null,"content":"I'm an Assistant Professor of Machine Learning at the University of Amsterdam and a member of AMLab. Previously, I was a postdoctoral research scientist with David Blei at the Data Science Institute, Columbia University. I completed my PhD in Electrical Engineering at Linköping University, advised by Fredrik Lindsten and Thomas Schön.\nMy research interests include approximate statistical inference, causality and artificial intelligence as well as their application to the life sciences.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://naesseth.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I'm an Assistant Professor of Machine Learning at the University of Amsterdam and a member of AMLab. Previously, I was a postdoctoral research scientist with David Blei at the Data Science Institute, Columbia University. I completed my PhD in Electrical Engineering at Linköping University, advised by Fredrik Lindsten and Thomas Schön.\nMy research interests include approximate statistical inference, causality and artificial intelligence as well as their application to the life sciences.","tags":null,"title":"","type":"authors"},{"authors":["Christian A. Naesseth","Fredrik Lindsten","David Blei"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608398807,"objectID":"a5bab444200c5016708910740efefc85","permalink":"https://naesseth.github.io/publication/naesseth-markovian-2020/","publishdate":"2020-12-19T17:26:47.620032Z","relpermalink":"/publication/naesseth-markovian-2020/","section":"publication","summary":"Modern variational inference (VI) uses stochastic gradients to avoid intractable expectations, enabling large-scale probabilistic inference in complex models. VI posits a family of approximating distributions q and then finds the member of that family that is closest to the exact posterior p. Traditionally, VI algorithms minimize the “exclusive Kullback-Leibler (KL)” KL(q||p), often for computational convenience. Recent research, however, has also focused on the “inclusive KL” KL(p||q), which has good statistical properties that makes it more appropriate for certain inference problems. This paper develops a simple algorithm for reliably minimizing the inclusive KL using stochastic gradients with vanishing bias. This method, which we call Markovian score climbing (MSC), converges to a local optimum of the inclusive KL. It does not suffer from the systematic errors inherent in existing methods, such as Reweighted Wake-Sleep and Neural Adaptive Sequential Monte Carlo, which lead to bias in their final estimates. We illustrate convergence on a toy model and demonstrate the utility of MSC on Bayesian probit regression for classification as well as a stochastic volatility model for financial data.","tags":[],"title":"Markovian Score Climbing: Variational Inference with KL(p||q)","type":"publication"},{"authors":["Christian A. Naesseth","Fredrik Lindsten","Thomas B. Schön"],"categories":[],"content":"","date":1572566400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608399388,"objectID":"79fed6ca5709cd3c9f865cc100a90dad","permalink":"https://naesseth.github.io/publication/naesseth-elements-2019/","publishdate":"2020-12-19T17:36:28.280935Z","relpermalink":"/publication/naesseth-elements-2019/","section":"publication","summary":"A core problem in statistics and probabilistic machine learning is to compute probability distributions and expectations. This is the fundamental problem of Bayesian statistics and machine learning, which frames all inference as expectations with respect to the posterior distribution. The key challenge is to approximate these intractable expectations. In this tutorial, we review sequential Monte Carlo (SMC), a random-samplingbased class of methods for approximate inference. First, we explain the basics of SMC, discuss practical issues, and review theoretical results. We then examine two of the main user design choices: the proposal distributions and the so called intermediate target distributions. We review recent results on how variational inference and amortization can be used to learn efficient proposals and target distributions. Next, we discuss the SMC estimate of the normalizing constant, how this can be used for pseudo-marginal inference and inference evaluation. Throughout the tutorial we illustrate the use of SMC on various models commonly used in machine learning, such as stochastic recurrent neural networks, probabilistic graphical models, and probabilistic programs.","tags":[],"title":"Elements of Sequential Monte Carlo","type":"publication"},{"authors":["Christian A. Naesseth","Fredrik Lindsten","Thomas B. Schön"],"categories":[],"content":"","date":1564617600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608399393,"objectID":"257e9a68a1ab8b3d2efd1b40d7b1ca8d","permalink":"https://naesseth.github.io/publication/naesseth-high-dimensional-2019/","publishdate":"2020-12-19T17:36:33.066316Z","relpermalink":"/publication/naesseth-high-dimensional-2019/","section":"publication","summary":"Sequential Monte Carlo (SMC) methods comprise one of the most successful approaches to approximate Bayesian filtering. However, SMC without a good proposal distribution can perform poorly, in particular in high dimensions. We propose nested sequential Monte Carlo, a methodology that generalizes the SMC framework by requiring only approximate, properly weighted, samples from the SMC proposal distribution, while still resulting in a correct SMC algorithm. This way, we can compute an “exact approximation” of, e.g., the locally optimal proposal, and extend the class of models for which we can perform efficient inference using SMC. We show improved accuracy over other state-of-the-art methods on several spatio-temporal state-space models.","tags":["\"Adaptation models\"","\"approximate Bayesian filtering\"","\"approximate Bayesian inference\"","\"backward simulation\"","\"Bayes methods\"","\"Biological system modeling\"","\"Computational modeling\"","\"exact approximation\"","\"filtering theory\"","\"high-dimensional filtering\"","\"locally optimal proposal\"","\"Monte Carlo methods\"","\"nested sequential Monte Carlo\"","\"Particle filtering\"","\"Probabilistic logic\"","\"Proposals\"","\"Sequential Monte Carlo methods\"","\"SMC proposal distribution\"","\"spatio-temporal models\"","\"state space models\"","\"state-space methods\""],"title":"High-Dimensional Filtering Using Nested Sequential Monte Carlo","type":"publication"},{"authors":["Christian A. Naesseth","Scott Linderman","Rajesh Ranganath","David Blei"],"categories":[],"content":"","date":1519862400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608399261,"objectID":"9024436bf8145e47b9d06b4e6b82cdd1","permalink":"https://naesseth.github.io/publication/naesseth-variational-2018/","publishdate":"2020-12-19T17:34:21.098459Z","relpermalink":"/publication/naesseth-variational-2018/","section":"publication","summary":"Many recent advances in large scale probabilistic inference rely on variational methods. The success of variational approaches depends on (i) formulating a flexible parametric family of distributions, and (ii) optimizing the parameters to find the member of this family that most closely approximates the exact posterior. In this paper we present a new approximating family of distributions, the variational sequential Monte Carlo (VSMC) family, and show how to optimize it in variational inference. VSMC melds variational inference (VI) and sequential Monte Carlo (SMC), providing practitioners with flexible, accurate, and powerful Bayesian inference. The VSMC family is a variational family that can approximate the posterior arbitrarily well, while still allowing for efficient optimization of its parameters. We demonstrate its utility on state space models, stochastic volatility models for financial data, and deep Markov models of brain neural circuits.","tags":[],"title":"Variational Sequential Monte Carlo","type":"publication"},{"authors":["Christian A. Naesseth"],"categories":[],"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608399522,"objectID":"c5a11f09d2c3d6f8a4f9763103871c18","permalink":"https://naesseth.github.io/publication/andersson-naesseth-machine-2018/","publishdate":"2020-12-19T17:38:41.99309Z","relpermalink":"/publication/andersson-naesseth-machine-2018/","section":"publication","summary":"Automatic decision making and pattern recognition under uncertainty are difficult tasks that are ubiquitous in our everyday life. The systems we design, and technology we develop, requires us to coherently represent and work with uncertainty in data. Probabilistic models and probabilistic inference gives us a powerful framework for solving this problem. Using this framework, while enticing, results in difficult-to-compute integrals and probabilities when conditioning on the observed data. This means we have a need for approximate inference, methods that solves the problem approximately using a systematic approach. In this thesis we develop new methods for efficient approximate inference in probabilistic models.\nThere are generally two approaches to approximate inference, variational methods and Monte Carlo methods. In Monte Carlo methods we use a large number of random samples to approximate the integral of interest. With variational methods, on the other hand, we turn the integration problem into that of an optimization problem. We develop algorithms of both types and bridge the gap between them.\nFirst, we present a self-contained tutorial to the popular sequential Monte Carlo (SMC) class of methods. Next, we propose new algorithms and applications based on SMC for approximate inference in probabilistic graphical models. We derive nested sequential Monte Carlo, a new algorithm particularly well suited for inference in a large class of high-dimensional probabilistic models. Then, inspired by similar ideas we derive interacting particle Markov chain Monte Carlo to make use of parallelization to speed up approximate inference for universal probabilistic programming languages. After that, we show how we can make use of the rejection sampling process when generating gamma distributed random variables to speed up variational inference. Finally, we bridge the gap between SMC and variational methods by developing variational sequential Monte Carlo, a new flexible family of variational approximations.","tags":[],"title":"Machine learning using approximate inference : Variational and sequential Monte Carlo methods","type":"publication"}]